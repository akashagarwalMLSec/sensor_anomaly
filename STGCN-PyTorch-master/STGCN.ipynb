{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"STGCN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"BtrBoXqCT0Rf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593569909159,"user_tz":240,"elapsed":2494,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}}},"source":["import os\n","import zipfile\n","import numpy as np\n","import torch"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKIeGz5bU-nc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1593539932076,"user_tz":240,"elapsed":15904,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}},"outputId":"83eff739-295a-47c0-fe6f-0fcfd793c6ef"},"source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","drive.flush_and_unmount()\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","drive.mount(ROOT)           # we mount the google drive at /content/drive"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive not mounted, so nothing to flush and unmount.\n","/content/drive\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oo0Hh1yEVIoI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593539934125,"user_tz":240,"elapsed":3004,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}},"outputId":"8c358213-e462-4397-9ed1-4ee6e993cc47"},"source":["%cd /content/drive/My\\ Drive/Colab\\ stuff/sensor_anomaly/STGCN-PyTorch-master\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab stuff/sensor_anomaly/STGCN-PyTorch-master\n","data  LICENSE  main.py\tREADME.md  STGCN.ipynb\tstgcn.py  utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rS4dcMd4T0Rk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593540240122,"user_tz":240,"elapsed":293,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}}},"source":["def load_metr_la_data():\n","    if (not os.path.isfile(\"data/adj_mat.npy\")\n","            or not os.path.isfile(\"data/node_values.npy\")):\n","        with zipfile.ZipFile(\"data/METR-LA.zip\", 'r') as zip_ref:\n","            zip_ref.extractall(\"data/\")\n","\n","    A = np.load(\"data/adj_mat.npy\")\n","    print(A[:,:5])\n","    X = np.load(\"data/node_values.npy\").transpose((1, 2, 0))\n","    print(A.shape, X.shape)\n","    X = X.astype(np.float32)\n","\n","    # Normalization using Z-score method\n","    means = np.mean(X, axis=(0, 2))\n","    X = X - means.reshape(1, -1, 1)\n","    stds = np.std(X, axis=(0, 2))\n","    X = X / stds.reshape(1, -1, 1)\n","\n","    return A, X, means, stds"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-u1X2WqT0Ru","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"status":"ok","timestamp":1593540240921,"user_tz":240,"elapsed":905,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}},"outputId":"070b679a-e9c1-4f6b-c9f2-29143c41ead9"},"source":["torch.manual_seed(7)\n","\n","A, X, means, stds = load_metr_la_data()\n","\n","split_line1 = int(X.shape[2] * 0.6)\n","split_line2 = int(X.shape[2] * 0.8)\n","\n","train_original_data = X[:, :, :split_line1]\n","val_original_data = X[:, :, split_line1:split_line2]\n","test_original_data = X[:, :, split_line2:]"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[[1.        0.        0.        0.        0.       ]\n"," [0.        1.        0.3909554 0.        0.       ]\n"," [0.        0.7174379 1.        0.        0.       ]\n"," ...\n"," [0.        0.        0.        0.        0.       ]\n"," [0.        0.        0.        0.        0.       ]\n"," [0.        0.        0.        0.        0.       ]]\n","(207, 207) (207, 2, 34272)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QeXl8_WlYG4x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593539951695,"user_tz":240,"elapsed":562,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}},"outputId":"af142a64-fba5-42f5-ab0b-a7868309653e"},"source":["print(\"Shape of features: {}\".format(X.shape))\n","print(\"Shape of Adjacency matrix: {}\".format(A.shape))\n","print(\"Shape of train_original_data: {}\".format(train_original_data.shape))\n","print(\"Shape of val_original_data: {}\".format(val_original_data.shape))\n","print(\"Shape of test_original_data: {}\".format(test_original_data.shape))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Shape of features: (207, 2, 34272)\n","Shape of Adjacency matrix: (207, 207)\n","Shape of train_original_data: (207, 2, 20563)\n","Shape of val_original_data: (207, 2, 6854)\n","Shape of test_original_data: (207, 2, 6855)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jfHn6h39WzuS","colab_type":"code","colab":{}},"source":["def generate_dataset(X, num_timesteps_input, num_timesteps_output):\n","    \"\"\"\n","    Takes node features for the graph and divides them into multiple samples\n","    along the time-axis by sliding a window of size (num_timesteps_input+\n","    num_timesteps_output) across it in steps of 1.\n","    :param X: Node features of shape (num_vertices, num_features,\n","    num_timesteps)\n","    :return:\n","        - Node features divided into multiple samples. Shape is\n","          (num_samples, num_vertices, num_features, num_timesteps_input).\n","        - Node targets for the samples. Shape is\n","          (num_samples, num_vertices, num_features, num_timesteps_output).\n","    \"\"\"\n","    # Generate the beginning index and the ending index of a sample, which\n","    # contains (num_points_for_training + num_points_for_predicting) points\n","    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n","               in range(X.shape[2] - (\n","                num_timesteps_input + num_timesteps_output) + 1)]\n","\n","    # Save samples\n","    features, target = [], []\n","    for i, j in indices:\n","        features.append(\n","            X[:, :, i: i + num_timesteps_input].transpose(\n","                (0, 2, 1)))\n","        target.append(X[:, 0, i + num_timesteps_input: j])\n","\n","    return torch.from_numpy(np.array(features)), \\\n","           torch.from_numpy(np.array(target))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tX6qAle_Wvda","colab_type":"code","colab":{}},"source":["training_input, training_target = generate_dataset(train_original_data,\n","                                                   num_timesteps_input=num_timesteps_input,\n","                                                   num_timesteps_output=num_timesteps_output)\n","val_input, val_target = generate_dataset(val_original_data,\n","                                         num_timesteps_input=num_timesteps_input,\n","                                         num_timesteps_output=num_timesteps_output)\n","test_input, test_target = generate_dataset(test_original_data,\n","                                           num_timesteps_input=num_timesteps_input,\n","                                           num_timesteps_output=num_timesteps_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vulgSbnwWqLj","colab_type":"code","colab":{}},"source":["def get_normalized_adj(A):\n","    \"\"\"\n","    Returns the degree normalized adjacency matrix.\n","    \"\"\"\n","    A = A + np.diag(np.ones(A.shape[0], dtype=np.float32))\n","    D = np.array(np.sum(A, axis=1)).reshape((-1,))\n","    D[D <= 10e-5] = 10e-5    # Prevent infs\n","    diag = np.reciprocal(np.sqrt(D))\n","    A_wave = np.multiply(np.multiply(diag.reshape((-1, 1)), A),\n","                         diag.reshape((1, -1)))\n","    return A_wave"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tK3Gg3YTT0Ry","colab_type":"code","colab":{}},"source":["A_wave = get_normalized_adj(A)\n","A_wave = torch.from_numpy(A_wave)\n","\n","A_wave = A_wave.to(device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuG0oJ6lT0Rn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593538859301,"user_tz":240,"elapsed":729,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class TimeBlock(nn.Module):\n","    \"\"\"\n","    Neural network block that applies a temporal convolution to each node of\n","    a graph in isolation.\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels, kernel_size=3):\n","        \"\"\"\n","        :param in_channels: Number of input features at each node in each time\n","        step.\n","        :param out_channels: Desired number of output channels at each node in\n","        each time step.\n","        :param kernel_size: Size of the 1D temporal kernel.\n","        \"\"\"\n","        super(TimeBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n","        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n","        self.conv3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n","\n","    def forward(self, X):\n","        \"\"\"\n","        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n","        num_features=in_channels)\n","        :return: Output data of shape (batch_size, num_nodes,\n","        num_timesteps_out, num_features_out=out_channels)\n","        \"\"\"\n","        # Convert into NCHW format for pytorch to perform convolutions.\n","        X = X.permute(0, 3, 1, 2)\n","        temp = self.conv1(X) + torch.sigmoid(self.conv2(X))\n","        out = F.relu(temp + self.conv3(X))\n","        # Convert back from NCHW to NHWC\n","        out = out.permute(0, 2, 3, 1)\n","        return out\n","\n","\n","class STGCNBlock(nn.Module):\n","    \"\"\"\n","    Neural network block that applies a temporal convolution on each node in\n","    isolation, followed by a graph convolution, followed by another temporal\n","    convolution on each node.\n","    \"\"\"\n","\n","    def __init__(self, in_channels, spatial_channels, out_channels,\n","                 num_nodes):\n","        \"\"\"\n","        :param in_channels: Number of input features at each node in each time\n","        step.\n","        :param spatial_channels: Number of output channels of the graph\n","        convolutional, spatial sub-block.\n","        :param out_channels: Desired number of output features at each node in\n","        each time step.\n","        :param num_nodes: Number of nodes in the graph.\n","        \"\"\"\n","        super(STGCNBlock, self).__init__()\n","        self.temporal1 = TimeBlock(in_channels=in_channels,\n","                                   out_channels=out_channels)\n","        self.Theta1 = nn.Parameter(torch.FloatTensor(out_channels,\n","                                                     spatial_channels))\n","        self.temporal2 = TimeBlock(in_channels=spatial_channels,\n","                                   out_channels=out_channels)\n","        self.batch_norm = nn.BatchNorm2d(num_nodes)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.Theta1.shape[1])\n","        self.Theta1.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, X, A_hat):\n","        \"\"\"\n","        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n","        num_features=in_channels).\n","        :param A_hat: Normalized adjacency matrix.\n","        :return: Output data of shape (batch_size, num_nodes,\n","        num_timesteps_out, num_features=out_channels).\n","        \"\"\"\n","        t = self.temporal1(X)\n","        lfs = torch.einsum(\"ij,jklm->kilm\", [A_hat, t.permute(1, 0, 2, 3)])\n","        # t2 = F.relu(torch.einsum(\"ijkl,lp->ijkp\", [lfs, self.Theta1]))\n","        t2 = F.relu(torch.matmul(lfs, self.Theta1))\n","        t3 = self.temporal2(t2)\n","        return self.batch_norm(t3)\n","        # return t3\n","\n","\n","class STGCN(nn.Module):\n","    \"\"\"\n","    Spatio-temporal graph convolutional network as described in\n","    https://arxiv.org/abs/1709.04875v3 by Yu et al.\n","    Input should have shape (batch_size, num_nodes, num_input_time_steps,\n","    num_features).\n","    \"\"\"\n","\n","    def __init__(self, num_nodes, num_features, num_timesteps_input,\n","                 num_timesteps_output):\n","        \"\"\"\n","        :param num_nodes: Number of nodes in the graph.\n","        :param num_features: Number of features at each node in each time step.\n","        :param num_timesteps_input: Number of past time steps fed into the\n","        network.\n","        :param num_timesteps_output: Desired number of future time steps\n","        output by the network.\n","        \"\"\"\n","        super(STGCN, self).__init__()\n","        self.block1 = STGCNBlock(in_channels=num_features, out_channels=64,\n","                                 spatial_channels=16, num_nodes=num_nodes)\n","        self.block2 = STGCNBlock(in_channels=64, out_channels=64,\n","                                 spatial_channels=16, num_nodes=num_nodes)\n","        self.last_temporal = TimeBlock(in_channels=64, out_channels=64)\n","        self.fully = nn.Linear((num_timesteps_input - 2 * 5) * 64,\n","                               num_timesteps_output)\n","\n","    def forward(self, A_hat, X):\n","        \"\"\"\n","        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n","        num_features=in_channels).\n","        :param A_hat: Normalized adjacency matrix.\n","        \"\"\"\n","        out1 = self.block1(X, A_hat)\n","        out2 = self.block2(out1, A_hat)\n","        out3 = self.last_temporal(out2)\n","        out4 = self.fully(out3.reshape((out3.shape[0], out3.shape[1], -1)))\n","        return out4"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"trFVrtqVT0Rr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593538911491,"user_tz":240,"elapsed":887,"user":{"displayName":"akash agarwal","photoUrl":"","userId":"01237904408123674076"}}},"source":["def train_epoch(training_input, training_target, batch_size):\n","    \"\"\"\n","    Trains one epoch with the given data.\n","    :param training_input: Training inputs of shape (num_samples, num_nodes,\n","    num_timesteps_train, num_features).\n","    :param training_target: Training targets of shape (num_samples, num_nodes,\n","    num_timesteps_predict).\n","    :param batch_size: Batch size to use during training.\n","    :return: Average loss for this epoch.\n","    \"\"\"\n","    permutation = torch.randperm(training_input.shape[0])\n","\n","    epoch_training_losses = []\n","    for i in range(0, training_input.shape[0], batch_size):\n","        net.train()\n","        optimizer.zero_grad()\n","\n","        indices = permutation[i:i + batch_size]\n","        X_batch, y_batch = training_input[indices], training_target[indices]\n","        X_batch = X_batch.to(device=device)\n","        y_batch = y_batch.to(device=device)\n","\n","        out = net(A_wave, X_batch)\n","        loss = loss_criterion(out, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_training_losses.append(loss.detach().cpu().numpy())\n","    return sum(epoch_training_losses)/len(epoch_training_losses)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-f3zrTtXFcX","colab_type":"code","colab":{}},"source":["import argparse\n","import pickle as pk\n","import matplotlib.pyplot as plt\n","\n","use_gpu = False\n","num_timesteps_input = 12\n","num_timesteps_output = 3\n","\n","epochs = 1000\n","batch_size = 50\n","\n","# parser = argparse.ArgumentParser(description='STGCN')\n","# parser.add_argument('--enable-cuda', action='store_true',\n","#                     help='Enable CUDA')\n","# args = parser.parse_args()\n","# args.device = None\n","# if args.enable_cuda and torch.cuda.is_available():\n","#     args.device = torch.device('cuda')\n","# else:\n","#     args.device = torch.device('cpu')\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print(\"Device: {}\".format(device))\n","net = STGCN(A_wave.shape[0],\n","            training_input.shape[3],\n","            num_timesteps_input,\n","            num_timesteps_output).to(device=device)\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n","loss_criterion = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxyqiRUCUPZQ","colab_type":"code","colab":{}},"source":["training_losses = []\n","validation_losses = []\n","validation_maes = []\n","for epoch in range(epochs):\n","    loss = train_epoch(training_input, training_target,\n","                       batch_size=batch_size)\n","    training_losses.append(loss)\n","\n","    # Run validation\n","    with torch.no_grad():\n","        net.eval()\n","        val_input = val_input.to(device=device)\n","        val_target = val_target.to(device=device)\n","\n","        out = net(A_wave, val_input)\n","        val_loss = loss_criterion(out, val_target).to(device=\"cpu\")\n","        validation_losses.append(np.asscalar(val_loss.detach().numpy()))\n","\n","        out_unnormalized = out.detach().cpu().numpy()*stds[0]+means[0]\n","        target_unnormalized = val_target.detach().cpu().numpy()*stds[0]+means[0]\n","        mae = np.mean(np.absolute(out_unnormalized - target_unnormalized))\n","        validation_maes.append(mae)\n","\n","        out = None\n","        val_input = val_input.to(device=\"cpu\")\n","        val_target = val_target.to(device=\"cpu\")\n","\n","    print(\"Training loss: {}\".format(training_losses[-1]))\n","    print(\"Validation loss: {}\".format(validation_losses[-1]))\n","    print(\"Validation MAE: {}\".format(validation_maes[-1]))\n","    plt.plot(training_losses, label=\"training loss\")\n","    plt.plot(validation_losses, label=\"validation loss\")\n","    plt.legend()\n","    plt.show()\n","\n","    checkpoint_path = \"checkpoints/\"\n","    if not os.path.exists(checkpoint_path):\n","        os.makedirs(checkpoint_path)\n","    with open(\"checkpoints/losses.pk\", \"wb\") as fd:\n","        pk.dump((training_losses, validation_losses, validation_maes), fd)"],"execution_count":null,"outputs":[]}]}