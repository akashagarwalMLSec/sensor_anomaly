{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metr_la_data():\n",
    "    if (not os.path.isfile(\"data/adj_mat.npy\")\n",
    "            or not os.path.isfile(\"data/node_values.npy\")):\n",
    "        with zipfile.ZipFile(\"data/METR-LA.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"data/\")\n",
    "\n",
    "    A = np.load(\"data/adj_mat.npy\")\n",
    "    X = np.load(\"data/node_values.npy\").transpose((1, 2, 0))\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Normalization using Z-score method\n",
    "    means = np.mean(X, axis=(0, 2))\n",
    "    X = X - means.reshape(1, -1, 1)\n",
    "    stds = np.std(X, axis=(0, 2))\n",
    "    X = X / stds.reshape(1, -1, 1)\n",
    "\n",
    "    return A, X, means, stds\n",
    "\n",
    "def get_normalized_adj(A):\n",
    "    \"\"\"\n",
    "    Returns the degree normalized adjacency matrix.\n",
    "    \"\"\"\n",
    "    A = A + np.diag(np.ones(A.shape[0], dtype=np.float32))\n",
    "    D = np.array(np.sum(A, axis=1)).reshape((-1,))\n",
    "    D[D <= 10e-5] = 10e-5    # Prevent infs\n",
    "    diag = np.reciprocal(np.sqrt(D))\n",
    "    A_wave = np.multiply(np.multiply(diag.reshape((-1, 1)), A),\n",
    "                         diag.reshape((1, -1)))\n",
    "    return A_wave\n",
    "\n",
    "def generate_dataset(X, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node features divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        - Node targets for the samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_output).\n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    features, target = [], []\n",
    "    for i, j in indices:\n",
    "        features.append(\n",
    "            X[:, :, i: i + num_timesteps_input].transpose(\n",
    "                (0, 2, 1)))\n",
    "        target.append(X[:, 0, i + num_timesteps_input: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(features)), \\\n",
    "           torch.from_numpy(np.array(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TimeBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a temporal convolution to each node of\n",
    "    a graph in isolation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input features at each node in each time\n",
    "        step.\n",
    "        :param out_channels: Desired number of output channels at each node in\n",
    "        each time step.\n",
    "        :param kernel_size: Size of the 1D temporal kernel.\n",
    "        \"\"\"\n",
    "        super(TimeBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels)\n",
    "        :return: Output data of shape (batch_size, num_nodes,\n",
    "        num_timesteps_out, num_features_out=out_channels)\n",
    "        \"\"\"\n",
    "        # Convert into NCHW format for pytorch to perform convolutions.\n",
    "        X = X.permute(0, 3, 1, 2)\n",
    "        temp = self.conv1(X) + torch.sigmoid(self.conv2(X))\n",
    "        out = F.relu(temp + self.conv3(X))\n",
    "        # Convert back from NCHW to NHWC\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class STGCNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a temporal convolution on each node in\n",
    "    isolation, followed by a graph convolution, followed by another temporal\n",
    "    convolution on each node.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, spatial_channels, out_channels,\n",
    "                 num_nodes):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input features at each node in each time\n",
    "        step.\n",
    "        :param spatial_channels: Number of output channels of the graph\n",
    "        convolutional, spatial sub-block.\n",
    "        :param out_channels: Desired number of output features at each node in\n",
    "        each time step.\n",
    "        :param num_nodes: Number of nodes in the graph.\n",
    "        \"\"\"\n",
    "        super(STGCNBlock, self).__init__()\n",
    "        self.temporal1 = TimeBlock(in_channels=in_channels,\n",
    "                                   out_channels=out_channels)\n",
    "        self.Theta1 = nn.Parameter(torch.FloatTensor(out_channels,\n",
    "                                                     spatial_channels))\n",
    "        self.temporal2 = TimeBlock(in_channels=spatial_channels,\n",
    "                                   out_channels=out_channels)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_nodes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.Theta1.shape[1])\n",
    "        self.Theta1.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, X, A_hat):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels).\n",
    "        :param A_hat: Normalized adjacency matrix.\n",
    "        :return: Output data of shape (batch_size, num_nodes,\n",
    "        num_timesteps_out, num_features=out_channels).\n",
    "        \"\"\"\n",
    "        t = self.temporal1(X)\n",
    "        lfs = torch.einsum(\"ij,jklm->kilm\", [A_hat, t.permute(1, 0, 2, 3)])\n",
    "        # t2 = F.relu(torch.einsum(\"ijkl,lp->ijkp\", [lfs, self.Theta1]))\n",
    "        t2 = F.relu(torch.matmul(lfs, self.Theta1))\n",
    "        t3 = self.temporal2(t2)\n",
    "        return self.batch_norm(t3)\n",
    "        # return t3\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-temporal graph convolutional network as described in\n",
    "    https://arxiv.org/abs/1709.04875v3 by Yu et al.\n",
    "    Input should have shape (batch_size, num_nodes, num_input_time_steps,\n",
    "    num_features).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, num_features, num_timesteps_input,\n",
    "                 num_timesteps_output):\n",
    "        \"\"\"\n",
    "        :param num_nodes: Number of nodes in the graph.\n",
    "        :param num_features: Number of features at each node in each time step.\n",
    "        :param num_timesteps_input: Number of past time steps fed into the\n",
    "        network.\n",
    "        :param num_timesteps_output: Desired number of future time steps\n",
    "        output by the network.\n",
    "        \"\"\"\n",
    "        super(STGCN, self).__init__()\n",
    "        self.block1 = STGCNBlock(in_channels=num_features, out_channels=64,\n",
    "                                 spatial_channels=16, num_nodes=num_nodes)\n",
    "        self.block2 = STGCNBlock(in_channels=64, out_channels=64,\n",
    "                                 spatial_channels=16, num_nodes=num_nodes)\n",
    "        self.last_temporal = TimeBlock(in_channels=64, out_channels=64)\n",
    "        self.fully = nn.Linear((num_timesteps_input - 2 * 5) * 64,\n",
    "                               num_timesteps_output)\n",
    "\n",
    "    def forward(self, A_hat, X):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps,\n",
    "        num_features=in_channels).\n",
    "        :param A_hat: Normalized adjacency matrix.\n",
    "        \"\"\"\n",
    "        out1 = self.block1(X, A_hat)\n",
    "        out2 = self.block2(out1, A_hat)\n",
    "        out3 = self.last_temporal(out2)\n",
    "        out4 = self.fully(out3.reshape((out3.shape[0], out3.shape[1], -1)))\n",
    "        return out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_gpu = False\n",
    "num_timesteps_input = 12\n",
    "num_timesteps_output = 3\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 50\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='STGCN')\n",
    "# parser.add_argument('--enable-cuda', action='store_true',\n",
    "#                     help='Enable CUDA')\n",
    "# args = parser.parse_args()\n",
    "# args.device = None\n",
    "# if args.enable_cuda and torch.cuda.is_available():\n",
    "#     args.device = torch.device('cuda')\n",
    "# else:\n",
    "#     args.device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def train_epoch(training_input, training_target, batch_size):\n",
    "    \"\"\"\n",
    "    Trains one epoch with the given data.\n",
    "    :param training_input: Training inputs of shape (num_samples, num_nodes,\n",
    "    num_timesteps_train, num_features).\n",
    "    :param training_target: Training targets of shape (num_samples, num_nodes,\n",
    "    num_timesteps_predict).\n",
    "    :param batch_size: Batch size to use during training.\n",
    "    :return: Average loss for this epoch.\n",
    "    \"\"\"\n",
    "    permutation = torch.randperm(training_input.shape[0])\n",
    "\n",
    "    epoch_training_losses = []\n",
    "    for i in range(0, training_input.shape[0], batch_size):\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        X_batch, y_batch = training_input[indices], training_target[indices]\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        y_batch = y_batch.to(device=device)\n",
    "\n",
    "        out = net(A_wave, X_batch)\n",
    "        loss = loss_criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_losses.append(loss.detach().cpu().numpy())\n",
    "    return sum(epoch_training_losses)/len(epoch_training_losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-217705091da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     loss = train_epoch(training_input, training_target,\n\u001b[0;32m---> 40\u001b[0;31m                        batch_size=batch_size)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtraining_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-82b44c3c814c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(training_input, training_target, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_wave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mepoch_training_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "A, X, means, stds = load_metr_la_data()\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.8)\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "\n",
    "training_input, training_target = generate_dataset(train_original_data,\n",
    "                                                   num_timesteps_input=num_timesteps_input,\n",
    "                                                   num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = generate_dataset(val_original_data,\n",
    "                                         num_timesteps_input=num_timesteps_input,\n",
    "                                         num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = generate_dataset(test_original_data,\n",
    "                                           num_timesteps_input=num_timesteps_input,\n",
    "                                           num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "A_wave = get_normalized_adj(A)\n",
    "A_wave = torch.from_numpy(A_wave)\n",
    "\n",
    "A_wave = A_wave.to(device=device)\n",
    "\n",
    "net = STGCN(A_wave.shape[0],\n",
    "            training_input.shape[3],\n",
    "            num_timesteps_input,\n",
    "            num_timesteps_output).to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_maes = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train_epoch(training_input, training_target,\n",
    "                       batch_size=batch_size)\n",
    "    training_losses.append(loss)\n",
    "\n",
    "    # Run validation\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        val_input = val_input.to(device=device)\n",
    "        val_target = val_target.to(device=device)\n",
    "\n",
    "        out = net(A_wave, val_input)\n",
    "        val_loss = loss_criterion(out, val_target).to(device=\"cpu\")\n",
    "        validation_losses.append(np.asscalar(val_loss.detach().numpy()))\n",
    "\n",
    "        out_unnormalized = out.detach().cpu().numpy()*stds[0]+means[0]\n",
    "        target_unnormalized = val_target.detach().cpu().numpy()*stds[0]+means[0]\n",
    "        mae = np.mean(np.absolute(out_unnormalized - target_unnormalized))\n",
    "        validation_maes.append(mae)\n",
    "\n",
    "        out = None\n",
    "        val_input = val_input.to(device=\"cpu\")\n",
    "        val_target = val_target.to(device=\"cpu\")\n",
    "\n",
    "    print(\"Training loss: {}\".format(training_losses[-1]))\n",
    "    print(\"Validation loss: {}\".format(validation_losses[-1]))\n",
    "    print(\"Validation MAE: {}\".format(validation_maes[-1]))\n",
    "    plt.plot(training_losses, label=\"training loss\")\n",
    "    plt.plot(validation_losses, label=\"validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    checkpoint_path = \"checkpoints/\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    with open(\"checkpoints/losses.pk\", \"wb\") as fd:\n",
    "        pk.dump((training_losses, validation_losses, validation_maes), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
